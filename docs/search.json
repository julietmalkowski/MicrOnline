[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "welcome!!!"
  },
  {
    "objectID": "environmental_parameter_analysis.html",
    "href": "environmental_parameter_analysis.html",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "Loading required package: permute\n\n\nLoading required package: lattice\n\n\nThis is vegan 2.6-4\n\n\nLoading required package: ape\n\n\nLoading required package: nlme\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:nlme':\n\n    collapse\n\n\nThe following object is masked from 'package:ape':\n\n    where\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nmicrobiome R package (microbiome.github.com)\n    \n\n\n Copyright (C) 2011-2022 Leo Lahti, \n    Sudarshan Shetty et al. &lt;microbiome.github.io&gt;\n\n\n\nAttaching package: 'microbiome'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    alpha\n\n\nThe following object is masked from 'package:vegan':\n\n    diversity\n\n\nThe following object is masked from 'package:base':\n\n    transform\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ microbiome::alpha() masks ggplot2::alpha()\n✖ dplyr::collapse()   masks nlme::collapse()\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::lag()        masks stats::lag()\n✖ dplyr::where()      masks ape::where()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAttaching package: 'reshape2'\n\n\nThe following object is masked from 'package:tidyr':\n\n    smiths\n\n\n\nAttaching package: 'ggpubr'\n\n\nThe following object is masked from 'package:ape':\n\n    rotate\n\n\n\n\n\notu_mat&lt;- read_excel(\"/Users/julietmalkowski/Desktop/Research/Kinetic_Model/abundance_table.xlsx\")\n#remove first 4 characters in every column name\ncolnames(otu_mat)&lt;- substr(colnames(otu_mat), 5, nchar(colnames(otu_mat)))\notu_mat = as.data.frame(otu_mat)\n#split first column by character '_' into two seperate columns\notu_mat[c('Process', 'Date')] &lt;- str_split_fixed(otu_mat$le, '_', 2)\n#drop le column\notu_mat = otu_mat[,-1]\n#move last two columns to the front\notu_mat &lt;- otu_mat %&gt;%\n  select(Process, everything())\notu_mat &lt;- otu_mat %&gt;%\n  select(Date, everything())\n#filter otu_mat to only contain AS-1 and AS-2 in process column\notu_mat &lt;- otu_mat %&gt;%\n  filter(Process == \"AS-1\" | Process == \"AS-2\")\n#remove Process column\notu_mat = otu_mat[,-2]\n#groupby date and find the mean of each column\notu_counts &lt;- otu_mat %&gt;%\n  group_by(Date) %&gt;%\n  summarise_all(mean)\notu_p = otu_counts\n#find the sum of each row\notu_p$sum &lt;- rowSums(otu_p[,-1])\n#divide each row by the sum\notu_p[,-1] &lt;- otu_p[,-1] / otu_p$sum\n#remove sum column\notu_p = otu_p[,-ncol(otu_p)]\n#make otu_p from wide form to long form\notu_p &lt;- otu_p %&gt;%\n  pivot_longer(cols = -Date, names_to = \"OTU\", values_to = \"Abundance\")\n#filter out rows with an Abundance less than 0.01\notu_p &lt;- otu_p %&gt;%\n  filter(Abundance &gt;= 0.01)\n#calculate Shannon Index and add it to otu_p column\nshannon = function(x) {\n  -sum(x * log(x))\n}\notu_shannon = otu_p\ns = otu_shannon %&gt;% group_by(Date) %&gt;%\n  summarize(Shannon = shannon(Abundance))\notu_shannon = merge(otu_shannon, s, by = \"Date\")\n\noutput_metadata &lt;- read_excel(\"/Users/julietmalkowski/Desktop/Research/Kinetic_Model/AS_metadata.xlsx\")\n\nNew names:\n• `` -&gt; `...1`\n\noutput_metadata = as.data.frame(output_metadata)\n\n#input parameters\ninput_metadata = output_metadata\ninput_metadata = input_metadata[,c(2,3,5,7,10,12,14,16,18,20)]\ninput_data = input_metadata\ninput_data = merge(otu_shannon, input_metadata, by = \"Date\")\n\n#output parameters\noutput_metadata = output_metadata[,-c(1,3:8,10,12,14:20)]\noutput_data = merge(otu_shannon, output_metadata, by = \"Date\")\n#change column 6 name\ncolnames(output_data)[6] &lt;- \"BOD_CBOD_Load_Removed\"\n#remove column in output_data\ninput_data_ = input_data[,-c(2:4)]\ninput_data_ = as.data.frame(input_data_)\n#remove duplicates\ninput_data_ = input_data_[!duplicated(input_data_[,1]),]\n#make first column rownames in output_data_\nrownames(input_data_) &lt;- input_data_[,1]\n#remove first column\ninput_data_ = input_data_[,-1]\n#move rowcols to first column\ninput_data_ = cbind(Date = rownames(input_data_), input_data_)\ninput_data_$Date &lt;- mdy(input_data_$Date)\n#remove rownames\nrownames(input_data_) &lt;- NULL\n\n#remove column in output_data\noutput_data_ = output_data[,-c(2:5)]\noutput_data_ = as.data.frame(output_data_)\n#remove duplicates\noutput_data_ = output_data_[!duplicated(output_data_[,1]),]\n#make first column rownames in output_data_\nrownames(output_data_) &lt;- output_data_[,1]\n#remove first column\noutput_data_ = output_data_[,-1]\n#move rowcols to first column\noutput_data_ = cbind(Date = rownames(output_data_), output_data_)\n#remove rownames\nrownames(output_data_) &lt;- NULL\n#make date column numeric\noutput_data_$Date &lt;- mdy(output_data_$Date)\n\n\n\n\n#RDA selected values only\n\ne = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = temp_RSS, color = \"temp_RSS\"),group = 1) +\n  ggtitle(\"RSS Temp Over Time\") + xlab(\"Month\") + ylab(\"temp (deg.C)\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nf = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = SCT_Detention_Time, color = \"SCT_Detention_Time\"),group = 1) + \n  ggtitle(\"SCT_Detention_Time Over Time\") + xlab(\"Month\") + ylab(\"time (hr)\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\ng = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = P_Load_PE, color = \"P_Load_PE\"),group = 1) + \n  ggtitle(\"P_Load_PE Over Time\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nh = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = TKN_Load_RAW, color = \"TKN_Load_RAW\"),group = 1) + \n  ggtitle(\"TKN_Load_RAW Over Time\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\ni = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = Ammonia_Load_RAW, color = \"Ammonia_Load_RAW\"),group = 1) + \n  ggtitle(\"Ammonia_Load_RAW\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nggarrange(e, f, g, h, i + rremove(\"x.text\"), \n          labels = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n          ncol = 2, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\na = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = BOD_CBOD_Load_Removed, color = \"BOD_CBOD_Load_Removed\"),group = 1) + \n  geom_line(data=output_data_,aes(x = Date, y = COD_Load_Removed,color = \"COD_Load_Removed\"),group = 1) +\n  ggtitle(\"Output Parameters Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nb = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = BOD_CBOD_Load_Removed, color = \"P_Removed\"),group = 1) + \n  ggtitle(\"P_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nc = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = TKN_Removed, color = \"TKN_Removed\"),group = 1) + \n  ggtitle(\"TKN_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nd = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = Ammonia_Removed, color = \"Ammonia_Removed\"),group = 1) + \n  ggtitle(\"Ammonia_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nggarrange(a, b, c, d + rremove(\"x.text\"), \n          labels = c(\"A\", \"B\", \"C\", \"D\"),\n          ncol = 2, nrow = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nggplot() + \n  geom_line(data=s,aes(x = Date,y = Shannon, color = \"Shannon\"),group = 1) + \n  ggtitle(\"Shannon Index Over Time\") + xlab(\"Date\") + ylab(\"Shannon Index\") + theme(legend.position=\"top\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n#put character z in front of all columns\ncolnames(otu_counts) &lt;- paste0(\"z\", colnames(otu_counts))\n#select only columns named '1' in otu_counts\notus &lt;- select(otu_counts,z1,z4,z2,z6,zDate)\n\n#plot the data\nggplot() + \n  geom_line(data=otus,aes(x = zDate, y = z1, color = \"1\"),group = 1) + \n  geom_line(data=otus,aes(x = zDate, y = z4,color = \"4\"),group = 1) +\n  geom_line(data=otus,aes(x = zDate, y = z2,color = \"2\"),group = 1) +\n  geom_line(data=otus,aes(x = zDate, y = z6 ,color = \"6\"),group = 1) +\n  ggtitle(\"OTU 1,4,2,6 Over Time\") + xlab(\"Date\") + ylab(\"Abundance\") + theme(legend.position=\"top\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "environmental_parameter_analysis.html#loading-metadata",
    "href": "environmental_parameter_analysis.html#loading-metadata",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "otu_mat&lt;- read_excel(\"/Users/julietmalkowski/Desktop/Research/Kinetic_Model/abundance_table.xlsx\")\n#remove first 4 characters in every column name\ncolnames(otu_mat)&lt;- substr(colnames(otu_mat), 5, nchar(colnames(otu_mat)))\notu_mat = as.data.frame(otu_mat)\n#split first column by character '_' into two seperate columns\notu_mat[c('Process', 'Date')] &lt;- str_split_fixed(otu_mat$le, '_', 2)\n#drop le column\notu_mat = otu_mat[,-1]\n#move last two columns to the front\notu_mat &lt;- otu_mat %&gt;%\n  select(Process, everything())\notu_mat &lt;- otu_mat %&gt;%\n  select(Date, everything())\n#filter otu_mat to only contain AS-1 and AS-2 in process column\notu_mat &lt;- otu_mat %&gt;%\n  filter(Process == \"AS-1\" | Process == \"AS-2\")\n#remove Process column\notu_mat = otu_mat[,-2]\n#groupby date and find the mean of each column\notu_counts &lt;- otu_mat %&gt;%\n  group_by(Date) %&gt;%\n  summarise_all(mean)\notu_p = otu_counts\n#find the sum of each row\notu_p$sum &lt;- rowSums(otu_p[,-1])\n#divide each row by the sum\notu_p[,-1] &lt;- otu_p[,-1] / otu_p$sum\n#remove sum column\notu_p = otu_p[,-ncol(otu_p)]\n#make otu_p from wide form to long form\notu_p &lt;- otu_p %&gt;%\n  pivot_longer(cols = -Date, names_to = \"OTU\", values_to = \"Abundance\")\n#filter out rows with an Abundance less than 0.01\notu_p &lt;- otu_p %&gt;%\n  filter(Abundance &gt;= 0.01)\n#calculate Shannon Index and add it to otu_p column\nshannon = function(x) {\n  -sum(x * log(x))\n}\notu_shannon = otu_p\ns = otu_shannon %&gt;% group_by(Date) %&gt;%\n  summarize(Shannon = shannon(Abundance))\notu_shannon = merge(otu_shannon, s, by = \"Date\")\n\noutput_metadata &lt;- read_excel(\"/Users/julietmalkowski/Desktop/Research/Kinetic_Model/AS_metadata.xlsx\")\n\nNew names:\n• `` -&gt; `...1`\n\noutput_metadata = as.data.frame(output_metadata)\n\n#input parameters\ninput_metadata = output_metadata\ninput_metadata = input_metadata[,c(2,3,5,7,10,12,14,16,18,20)]\ninput_data = input_metadata\ninput_data = merge(otu_shannon, input_metadata, by = \"Date\")\n\n#output parameters\noutput_metadata = output_metadata[,-c(1,3:8,10,12,14:20)]\noutput_data = merge(otu_shannon, output_metadata, by = \"Date\")\n#change column 6 name\ncolnames(output_data)[6] &lt;- \"BOD_CBOD_Load_Removed\"\n#remove column in output_data\ninput_data_ = input_data[,-c(2:4)]\ninput_data_ = as.data.frame(input_data_)\n#remove duplicates\ninput_data_ = input_data_[!duplicated(input_data_[,1]),]\n#make first column rownames in output_data_\nrownames(input_data_) &lt;- input_data_[,1]\n#remove first column\ninput_data_ = input_data_[,-1]\n#move rowcols to first column\ninput_data_ = cbind(Date = rownames(input_data_), input_data_)\ninput_data_$Date &lt;- mdy(input_data_$Date)\n#remove rownames\nrownames(input_data_) &lt;- NULL\n\n#remove column in output_data\noutput_data_ = output_data[,-c(2:5)]\noutput_data_ = as.data.frame(output_data_)\n#remove duplicates\noutput_data_ = output_data_[!duplicated(output_data_[,1]),]\n#make first column rownames in output_data_\nrownames(output_data_) &lt;- output_data_[,1]\n#remove first column\noutput_data_ = output_data_[,-1]\n#move rowcols to first column\noutput_data_ = cbind(Date = rownames(output_data_), output_data_)\n#remove rownames\nrownames(output_data_) &lt;- NULL\n#make date column numeric\noutput_data_$Date &lt;- mdy(output_data_$Date)"
  },
  {
    "objectID": "environmental_parameter_analysis.html#input-visualization",
    "href": "environmental_parameter_analysis.html#input-visualization",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "#RDA selected values only\n\ne = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = temp_RSS, color = \"temp_RSS\"),group = 1) +\n  ggtitle(\"RSS Temp Over Time\") + xlab(\"Month\") + ylab(\"temp (deg.C)\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nf = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = SCT_Detention_Time, color = \"SCT_Detention_Time\"),group = 1) + \n  ggtitle(\"SCT_Detention_Time Over Time\") + xlab(\"Month\") + ylab(\"time (hr)\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\ng = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = P_Load_PE, color = \"P_Load_PE\"),group = 1) + \n  ggtitle(\"P_Load_PE Over Time\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nh = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = TKN_Load_RAW, color = \"TKN_Load_RAW\"),group = 1) + \n  ggtitle(\"TKN_Load_RAW Over Time\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\ni = ggplot() + \n  geom_line(data=input_data_,aes(x = Date,y = Ammonia_Load_RAW, color = \"Ammonia_Load_RAW\"),group = 1) + \n  ggtitle(\"Ammonia_Load_RAW\") + xlab(\"Month\") + ylab(\"mg/L\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nggarrange(e, f, g, h, i + rremove(\"x.text\"), \n          labels = c(\"A\", \"B\", \"C\", \"D\", \"E\"),\n          ncol = 2, nrow = 3)"
  },
  {
    "objectID": "environmental_parameter_analysis.html#output-visualization",
    "href": "environmental_parameter_analysis.html#output-visualization",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "a = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = BOD_CBOD_Load_Removed, color = \"BOD_CBOD_Load_Removed\"),group = 1) + \n  geom_line(data=output_data_,aes(x = Date, y = COD_Load_Removed,color = \"COD_Load_Removed\"),group = 1) +\n  ggtitle(\"Output Parameters Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nb = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = BOD_CBOD_Load_Removed, color = \"P_Removed\"),group = 1) + \n  ggtitle(\"P_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nc = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = TKN_Removed, color = \"TKN_Removed\"),group = 1) + \n  ggtitle(\"TKN_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nd = ggplot() + \n  geom_line(data=output_data_,aes(x = Date,y = Ammonia_Removed, color = \"Ammonia_Removed\"),group = 1) + \n  ggtitle(\"Ammonia_Removed Over Time\") + xlab(\"Month\") + ylab(\"tonnes/day\") + \n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%m\") + theme(legend.position=\"top\")\n\nggarrange(a, b, c, d + rremove(\"x.text\"), \n          labels = c(\"A\", \"B\", \"C\", \"D\"),\n          ncol = 2, nrow = 2)"
  },
  {
    "objectID": "environmental_parameter_analysis.html#shannon-index-visualization",
    "href": "environmental_parameter_analysis.html#shannon-index-visualization",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "ggplot() + \n  geom_line(data=s,aes(x = Date,y = Shannon, color = \"Shannon\"),group = 1) + \n  ggtitle(\"Shannon Index Over Time\") + xlab(\"Date\") + ylab(\"Shannon Index\") + theme(legend.position=\"top\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "environmental_parameter_analysis.html#otu-1426-visualization",
    "href": "environmental_parameter_analysis.html#otu-1426-visualization",
    "title": "Environmental Parameter Analysis",
    "section": "",
    "text": "#put character z in front of all columns\ncolnames(otu_counts) &lt;- paste0(\"z\", colnames(otu_counts))\n#select only columns named '1' in otu_counts\notus &lt;- select(otu_counts,z1,z4,z2,z6,zDate)\n\n#plot the data\nggplot() + \n  geom_line(data=otus,aes(x = zDate, y = z1, color = \"1\"),group = 1) + \n  geom_line(data=otus,aes(x = zDate, y = z4,color = \"4\"),group = 1) +\n  geom_line(data=otus,aes(x = zDate, y = z2,color = \"2\"),group = 1) +\n  geom_line(data=otus,aes(x = zDate, y = z6 ,color = \"6\"),group = 1) +\n  ggtitle(\"OTU 1,4,2,6 Over Time\") + xlab(\"Date\") + ylab(\"Abundance\") + theme(legend.position=\"top\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "fourier_transform.html",
    "href": "fourier_transform.html",
    "title": "Fourier Discrete Transform of Count Data",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd"
  },
  {
    "objectID": "fourier_transform.html#creating-count-data",
    "href": "fourier_transform.html#creating-count-data",
    "title": "Fourier Discrete Transform of Count Data",
    "section": "Creating Count Data",
    "text": "Creating Count Data\n\nabundance_table = pd.read_excel('/Users/julietmalkowski/Desktop/Research/Kinetic_Model/abundance_table.xlsx')\n#remove first 4 characters in every column name\nabundance_table.columns = abundance_table.columns.str[4:] \n#split string in column to get date and process\nabundance_table[['Process','Date']] = abundance_table['le'].str.split('_',expand=True)\nabundance_table = abundance_table.drop(columns=['le'])\n#keep only AS-1 and AS-2 data\nprocesses = ['AS-1', 'AS-2']\nas_abundance_table = abundance_table[abundance_table['Process'].isin(processes)]\nas_abundance_table = as_abundance_table.drop(columns=['Process'])\n#group by date and find the mean of all values\nas_abundance_table = as_abundance_table.groupby(['Date']).mean()\n\n\nShow Count Data\n\n#remove last two rows of as_abundance_table\na = as_abundance_table.iloc[:,:-2]\na = a.reset_index()\nprint(a.head())\n#remove first column in a\na = a.iloc[:,1:]\n#tranform to numpy array\na = a.to_numpy()\n\n         Date   121   22       4    61  9124   190    33   70  1716  ...  \\\n0  01/05/2023  66.5  0.0   267.5  27.0   0.0  17.0  34.0  0.5   0.0  ...   \n1  01/10/2023  86.0  0.0  1260.0  35.0   0.0  32.0  43.0  0.0   0.0  ...   \n2  01/12/2023  38.5  0.0   374.5  10.0   0.0  12.0  38.5  0.5   0.0  ...   \n3  01/17/2023  41.0  0.0   738.0  10.0   0.0  28.5  45.0  0.0   1.0  ...   \n4  01/19/2023  39.0  0.0   616.5  16.0   0.0  29.0  98.0  0.0   0.0  ...   \n\n   9558  12913  10999  13677  17024  11155  10242  6130  15569  17515  \n0   0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0  \n1   0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0  \n2   0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0  \n3   0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0  \n4   0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0    0.0  \n\n[5 rows x 16033 columns]"
  },
  {
    "objectID": "fourier_transform.html#fourier-transform-of-count-data",
    "href": "fourier_transform.html#fourier-transform-of-count-data",
    "title": "Fourier Discrete Transform of Count Data",
    "section": "Fourier Transform of Count Data",
    "text": "Fourier Transform of Count Data\n\ndef FFT(input_array):\n\n    fig, ax = plt.subplots(2, 1, figsize=(10, 10))\n\n    #Taking each OTU and fourier transforming its signal through time\n    for i in range(input_array.shape[1]):\n        ax[0].plot(input_array[:,i])\n\n        #Calculate the FFT\n        #calculate fourier transform by using np.fft.fft to calculate fft of each column (each OTU count through time)\n        #calculate the fourier sample frequencies by using np.fft.fftfreq\n        #Use np.fft.fftshift to shift the zero-frequency component to the center of the spectrum.\n\n        fft = np.fft.fftshift(np.fft.fft(input_array[:,i]))\n        fft_freq = np.fft.fftshift(np.fft.fftfreq(len(fft)))\n\n        fft = np.abs(fft[fft_freq &gt; 0])\n        fft_freq = fft_freq[fft_freq &gt; 0]\n\n        ax[1].plot(fft_freq, fft)\n\n    ax[0].set_title('Input signal')\n    ax[0].set_xlabel('Time')\n    ax[0].set_ylabel('Amplitude')\n\n    ax[1].set_title('FFT of the signal')\n    ax[1].set_xlabel('Frequency')\n    ax[1].set_ylabel('Amplitude')\n\n    plt.show()\n\nFFT(a.copy())"
  },
  {
    "objectID": "correlation_matrix.html",
    "href": "correlation_matrix.html",
    "title": "Correlations",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport scipy.stats"
  },
  {
    "objectID": "correlation_matrix.html#loading-data",
    "href": "correlation_matrix.html#loading-data",
    "title": "Correlations",
    "section": "Loading Data",
    "text": "Loading Data\n\nabundance_table = pd.read_excel(\"/Users/julietmalkowski/Desktop/Research/Kinetic_Model/abundance_table.xlsx\")\n#remove first 4 characters in every column name\nabundance_table.columns = abundance_table.columns.str[4:] \n#split string in column to get date and process\nabundance_table[['Process','Date']] = abundance_table['le'].str.split('_',expand=True)\nabundance_table = abundance_table.drop(columns=['le'])\nprocesses = ['AS-1', 'AS-2']\nas_abundance_table = abundance_table[abundance_table['Process'].isin(processes)]\nas_abundance_table = as_abundance_table.drop(columns=['Process'])\n#group by date and find the mean of all values\nas_abundance_table = as_abundance_table.groupby(['Date']).mean()\n#remove last two rows of as_abundance_table\na = as_abundance_table.iloc[:,:-2]\na = a.reset_index()\n#remove first column in a\na = a.iloc[:,1:]\na = a.to_numpy()"
  },
  {
    "objectID": "correlation_matrix.html#correlation-between-count-data",
    "href": "correlation_matrix.html#correlation-between-count-data",
    "title": "Correlations",
    "section": "Correlation between count data",
    "text": "Correlation between count data\n\ncorrelation = np.corrcoef(a.T)\n\nmask = ((correlation &gt; 0.75) & (correlation &lt; 0.99)) | (correlation &lt; -0.75) & (correlation &gt; -0.99)\n\n# Plotting\nfig = plt.figure()\n# Put in title and axis labels\nfig.suptitle('Correlation Matrix of OTU Counts Over Time')\nax = fig.add_subplot(111)\n\n# Use the mask to display the significant correlations\nmasked_correlation = np.ma.masked_where(~mask, correlation)\ncax = ax.matshow(masked_correlation, cmap='coolwarm', vmin=-1, vmax=1)\nfig.colorbar(cax)\n\nplt.show()\n\n/Users/julietmalkowski/Desktop/Research/Micro/env/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:2922: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[:, None]\n/Users/julietmalkowski/Desktop/Research/Micro/env/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:2923: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[None, :]"
  },
  {
    "objectID": "trend_decomposition.html",
    "href": "trend_decomposition.html",
    "title": "Decomposition of Trends",
    "section": "",
    "text": "import pandas as pd\nfrom scipy import interpolate\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nfrom random import gauss\nfrom pandas.plotting import autocorrelation_plot\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')"
  },
  {
    "objectID": "trend_decomposition.html#seasonal-decomposition",
    "href": "trend_decomposition.html#seasonal-decomposition",
    "title": "Decomposition of Trends",
    "section": "Seasonal Decomposition",
    "text": "Seasonal Decomposition\n\nunfiltered_data = unfiltered_data\ndecomposition = sm.tsa.seasonal_decompose(unfiltered_data['Shannon Index'], period = 4) \nfigure = decomposition.plot()\nplt.show()"
  },
  {
    "objectID": "trend_decomposition.html#shannon-index-over-time",
    "href": "trend_decomposition.html#shannon-index-over-time",
    "title": "Decomposition of Trends",
    "section": "Shannon Index over time",
    "text": "Shannon Index over time\n\n#plot Shannon Index over time with angle = 90 on x-axis labels\nplt.xticks(rotation=90, size = 5)\nsns.lineplot(x='Date', y='Shannon Index', data=unfiltered_data)\nplt.title('Shannon Index Over Time')\n#add x-axis label\nplt.xlabel('Date')\nplt.xticks(size = 10)\n\n(array([19174., 19236., 19297., 19358., 19417., 19478.]),\n [Text(19174.0, 0, '2022-07'),\n  Text(19236.0, 0, '2022-09'),\n  Text(19297.0, 0, '2022-11'),\n  Text(19358.0, 0, '2023-01'),\n  Text(19417.0, 0, '2023-03'),\n  Text(19478.0, 0, '2023-05')])"
  }
]